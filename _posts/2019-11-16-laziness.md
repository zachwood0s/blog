---
layout: post
title: "Lazy Evaluation and Infinite Data Structures"
---

This is the third article in the functional programming series.

- [Functional Programming]({% link _posts/2019-11-15-intro-to-functiona.md %})
- [Higher-Order Functions]({% link _posts/2019-11-16-higher-order-functions.md %})
- *Laziness and Infinite Data Structures*

# Lazy Evaluation

Let's start off by defining lazy evaluation.

>  [Lazy Evaluation] means that expressions are not evaluated when they are bound to variables, but their evaluation is deferred until their results are needed by other computations.

In other words, lazy languages will not evaluate something unless they absolutely have to. This means that if we had a list of expensive computations but only wanted the first, only the first computation would be run.

```haskell
head [expensive1, expensive2, expensive3, ...]
-- Outputs: expensive1 
-- Note: expensive2, expensive3, ... 
--       were not run because the result did not depend on them. 
```

## Why is This Useful?

There are a few reasons that this method of evaluation could be useful. In some cases, it is more efficient to do it this way. We can eliminate lots of costly evaluations by waiting until they're absolutely required. In other languages, you can do this as well, but you'd have to do it manually. One of the biggest reasons this is useful, however, is that you can write certain algorithms in a cleaner, more succinct way. 

#### Finding the Minimum

Typically when you're finding the minimum of a list, you have to loop through a list and then keep track of what the current minimum is, changing it every time you find a new smallest element. While you could do that in a lazy language, you could also approach the problem in a different way. If you were given a sorted list, then the smallest element would always be the first. So to find the minimum, you could just sort the list and take the first element. However, in most languages, sorting the entire list just to take the first would be incredibly inefficient. But, in Haskell, the sort function is lazy. Meaning if we say 

> Sort the list and take the first `k` elements

Haskell will only sort the first k elements and then stop. Because of this, we can write our minimum function like so:

```haskell
minimum ls = head (sort ls)
```

Once again, we're defining what it means to be the smallest element rather than describing how to get it. We've defined the minimum to be the first element in a sorted list. 


## Infinite Data Structures

Another use-case for lazy evaluation is that it allows us to represent *infinite data structures*. For example, we could represent all of the integers like:

```haskell 
[1..]
```

Or we could have an infinite list of all 0's.

```haskell
repeat 0
```

The reason we're allowed to do this is that Haskell doesn't evaluate the list once we define it. It waits until we use it to actually compute anything. That means we still have to be a little careful with how we evaluate them. For example, if we tried to print the infinite list, we're going to have an issue. Haskell will just continue printing numbers until the end of the universe. It does allow us to represent some things quite elegantly, however. For example, the typical (naive) Fibanocci algorithm can be implemented like so:

```haskell
fib :: Integer -> Integer
fib 0 = 0
fib 1 = 1
fib n = fib (n-1) + fib (n-2)
```

With this algorithm, however, we're re-evaluating parts of the sequence multiple times. Instead, it would be better to build the list from the ground up, continuing infinitely. This way, we can rely on the results of our previous calculations. In an imperative world, this would look like:

```csharp
public static int GetNthFibonacci_Ite(int n)  
{  
    int number = n - 1; //Need to decrement by 1 since we are starting from 0  
    int[] Fib = new int[number + 1];  
    Fib[0]= 0;  
    Fib[1]= 1;  
    for (int i = 2; i <= number;i++)  
    {  
       Fib[i] = Fib[i - 2] + Fib[i - 1];  
    }  
    return Fib[number];  
} 
```
This doesn't continue infinitely but it allows us to retrieve the nth Fibonacci number and it uses the results of previous iterations to calculate this. In haskell, we could represent the same thing like:

```haskell
fibs = 1 : 1 : zipWith (+) fibs (tail fibs)
```

Here we start our infinite list with two values, `[1, 1]` and specify that the rest of the list can be found by `zipWith (+) fibs (tail fibs)`. This is a bit complicated, but essentially we're saying that we want to take our `fibs` list (`[1, 1, ...]`) and then take the tail of our `fibs` list (`[1, ...]`) and combine them into one list by adding each element together. Because Haskell is lazy, we're able to define `fibs` in terms of itself. 
[Here's a more in-depth explanation of what's going on in this implementation.](https://stackoverflow.com/questions/1105765/generating-fibonacci-numbers-in-haskell)

## Conclusion

Hopefully, these past three articles have given you a decent understanding of functional programming, its features, and its benefits. Functional programming isn't a cure-all paradigm, but it does provide a bunch of nice features that can help make code more concise and more expressive. Also, functional programming isn't restricted to pure functional languages. Most modern languages have a mixture of paradigms meaning you can most likely apply the concepts from these articles. If you're looking for more info on a functional language, I would check out the online book [Learn You A Haskell](http://learnyouahaskell.com/). It has tons of great information and covers the topics discussed in these articles in great detail.
